version: "3.7"

services:
  redis:
    image: redis:6
    container_name: redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

  airflow:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow
    depends_on:
      redis:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "sqlite:////opt/airflow/airflow.db"
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      INPUT_CSV: /opt/airflow/data/novas_empresas.csv
      REDIS_HOST: redis
      REDIS_PORT: 6379
      SPARK_MASTER: local[2]
      _AIRFLOW_WWW_USER_USERNAME: cayoesn
      _AIRFLOW_WWW_USER_PASSWORD: 123456789
      _AIRFLOW_WWW_USER_FIRSTNAME: Cayo
      _AIRFLOW_WWW_USER_LASTNAME: Neves
      _AIRFLOW_WWW_USER_EMAIL: cayo@example.com
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
    ports:
      - "8080:8080"
    command: bash -c "airflow scheduler & airflow webserver"

  redisinsight:
    image: redis/redisinsight:latest
    container_name: redisinsight
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "5540:5540"
    restart: unless-stopped
    volumes:
      - redisinsight_data:/data
    environment:
      - RI_APP_PORT=5540
      - RI_APP_HOST=0.0.0.0
      - RI_REDIS_HOST=redis
      - RI_REDIS_PORT=6379

  tests:
    build:
      context: .
      dockerfile: Dockerfile.test
    container_name: tests
    volumes:
      - ./:/app

volumes:
  redisinsight_data:
